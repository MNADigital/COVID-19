{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import date, datetime, timedelta\n",
    "import untangle # xml\n",
    "import requests # json\n",
    "import re # regular expressions\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "today = date.today()\n",
    "yesterday = date.today() - timedelta(days=1)\n",
    "\n",
    "our_utla_codes = [\n",
    "    'E08000025', # Birmingham\n",
    "    'E08000027', # Dudley\n",
    "    'E08000028', # Sandwell\n",
    "    'E06000051', # Shropshire\n",
    "    'E10000028', # Staffordshire\n",
    "    'E06000021', # Stoke-on-Trent\n",
    "    'E06000020', # Telford and Wrekin\n",
    "    'E08000030', # Walsall\n",
    "    'E08000031', # Wolverhampton\n",
    "    'E10000034', # Worcestershire\n",
    "]\n",
    "utlacodes_expressandstar = [\n",
    "    'E08000025', # Birmingham\n",
    "    'E08000027', # Dudley\n",
    "    'E08000028', # Sandwell\n",
    "    'E10000028', # Staffordshire\n",
    "    'E06000021', # Stoke-on-Trent\n",
    "    'E08000030', # Walsall\n",
    "    'E08000031', # Wolverhampton\n",
    "]\n",
    "utlacodes_blackcountry = [\n",
    "    'E08000027', # Dudley\n",
    "    'E08000028', # Sandwell\n",
    "    'E08000030', # Walsall\n",
    "    'E08000031', # Wolverhampton\n",
    "]\n",
    "utlacodes_blackcountryandbirmingham = [\n",
    "    'E08000025', # Birmingham\n",
    "    'E08000027', # Dudley\n",
    "    'E08000028', # Sandwell\n",
    "    'E08000030', # Walsall\n",
    "    'E08000031', # Wolverhampton\n",
    "]\n",
    "utlacodes_sandwellandbirmingham = [\n",
    "    'E08000025', # Birmingham\n",
    "    'E08000028', # Sandwell\n",
    "]\n",
    "utlacodes_staffordshire = [\n",
    "    'E10000028', # Staffordshire\n",
    "]\n",
    "utlacodes_wolverhampton = [\n",
    "    'E08000031', # Wolverhampton\n",
    "]\n",
    "utlacodes_walsall = [\n",
    "    'E08000030', # Walsall\n",
    "]\n",
    "utlacodes_dudley = [\n",
    "    'E08000027', # Dudley\n",
    "]\n",
    "utlacodes_sandwell = [\n",
    "    'E08000028', # Sandwell\n",
    "]\n",
    "utlacodes_birmingham = [\n",
    "    'E08000025', # Birmingham\n",
    "]\n",
    "utlacodes_stoke = [\n",
    "    'E06000021', # Stoke-on-Trent\n",
    "]\n",
    "utlacodes_staffordshireandstoke = [\n",
    "    'E10000028', # Staffordshire\n",
    "    'E06000021', # Stoke-on-Trent\n",
    "]\n",
    "utlacodes_worcestershire = [\n",
    "    'E10000034', # Worcestershire\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull the XML and traverse to the blobs\n",
    "xmlblobs = untangle.parse(\n",
    "    'https://publicdashacc.blob.core.windows.net/publicdata?restype=container&comp=list'\n",
    ").EnumerationResults.Blobs.Blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the cdata of the names, filter to pattern, map to an object while extracting the date\n",
    "\n",
    "pattern = '^data_([0-9]{4}(0[0-9]|1[0-2])([0-2][0-9]|3[0-1])).+\\.json$'\n",
    "datafiles = list(\n",
    "    map(\n",
    "        lambda filename: {\n",
    "            'date': datetime.strptime(\n",
    "                re.search(pattern,filename).group(1),\n",
    "                '%Y%m%d'\n",
    "            ),\n",
    "            'filename': filename\n",
    "        },\n",
    "        filter(\n",
    "            lambda filename: re.search(pattern,filename),\n",
    "            map(\n",
    "                lambda blob: blob.Name.cdata,\n",
    "                xmlblobs\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'date': datetime.datetime(2020, 4, 9, 0, 0),\n",
       "  'filename': 'data_202004091537.json'},\n",
       " {'date': datetime.datetime(2020, 4, 10, 0, 0),\n",
       "  'filename': 'data_202004101527.json'},\n",
       " {'date': datetime.datetime(2020, 4, 11, 0, 0),\n",
       "  'filename': 'data_202004111452.json'},\n",
       " {'date': datetime.datetime(2020, 4, 12, 0, 0),\n",
       "  'filename': 'data_202004121411.json'},\n",
       " {'date': datetime.datetime(2020, 4, 13, 0, 0),\n",
       "  'filename': 'data_202004131413.json'},\n",
       " {'date': datetime.datetime(2020, 4, 14, 0, 0),\n",
       "  'filename': 'data_202004141435.json'},\n",
       " {'date': datetime.datetime(2020, 4, 14, 0, 0),\n",
       "  'filename': 'data_202004141544.json'},\n",
       " {'date': datetime.datetime(2020, 4, 15, 0, 0),\n",
       "  'filename': 'data_202004151454.json'},\n",
       " {'date': datetime.datetime(2020, 4, 16, 0, 0),\n",
       "  'filename': 'data_202004161444.json'},\n",
       " {'date': datetime.datetime(2020, 4, 17, 0, 0),\n",
       "  'filename': 'data_202004171502.json'},\n",
       " {'date': datetime.datetime(2020, 4, 18, 0, 0),\n",
       "  'filename': 'data_202004181457.json'},\n",
       " {'date': datetime.datetime(2020, 4, 19, 0, 0),\n",
       "  'filename': 'data_202004191500.json'},\n",
       " {'date': datetime.datetime(2020, 4, 19, 0, 0),\n",
       "  'filename': 'data_202004191513.json'},\n",
       " {'date': datetime.datetime(2020, 4, 20, 0, 0),\n",
       "  'filename': 'data_202004201559.json'}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datafiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utla_day_to_dataframe(xmljsonref):\n",
    "    # build a url to retrieve\n",
    "    url = 'https://c19pub.azureedge.net/' + xmljsonref['filename']\n",
    "    \n",
    "    # request a URL ( I should really add a fail state which removes this file from the list )\n",
    "    json = requests.get(url).json()\n",
    "    \n",
    "    # empty array :facepalm:\n",
    "    utla_data = []\n",
    "    \n",
    "    # iterate through utlas element of JSON\n",
    "    for (code, data) in json['utlas'].items():\n",
    "        # if the code is one of our UTLAs\n",
    "        if code in our_utla_codes:\n",
    "            # loop through the days of data in the dailyConfirmedCases element\n",
    "            for day in data['dailyConfirmedCases']:\n",
    "                # append a mix of this data and that above\n",
    "                utla_data.append([\n",
    "                    code, # UTLA code\n",
    "                    data['name']['value'], # filename\n",
    "                    day['date'], # date of cases\n",
    "                    day['value'] # cases\n",
    "                ])\n",
    "    xmljsonref['dataframe'] = pd.DataFrame(data=utla_data, columns=['code','name','date of cases','cases'])\n",
    "    \n",
    "    return xmljsonref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_add_reported_day(x):\n",
    "    x['dataframe']['date reported'] = x['date']\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_utlas_historical = reduce(\n",
    "    lambda all_data, day_data : all_data.append(day_data,ignore_index=True),\n",
    "    map(\n",
    "        lambda x : x['dataframe'],\n",
    "        map(\n",
    "            map_add_reported_day,\n",
    "            map(utla_day_to_dataframe, datafiles)\n",
    "        )\n",
    "    ),\n",
    "    pd.DataFrame(columns = ['code','name','date of cases','date reported','cases'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>name</th>\n",
       "      <th>date of cases</th>\n",
       "      <th>date reported</th>\n",
       "      <th>cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E08000025</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>2020-04-09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E08000025</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>2020-03-02</td>\n",
       "      <td>2020-04-09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E08000025</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>2020-03-05</td>\n",
       "      <td>2020-04-09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E08000025</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>2020-03-08</td>\n",
       "      <td>2020-04-09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E08000025</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>2020-03-09</td>\n",
       "      <td>2020-04-09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5029</th>\n",
       "      <td>E10000034</td>\n",
       "      <td>Worcestershire</td>\n",
       "      <td>2020-04-15</td>\n",
       "      <td>2020-04-20</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5030</th>\n",
       "      <td>E10000034</td>\n",
       "      <td>Worcestershire</td>\n",
       "      <td>2020-04-16</td>\n",
       "      <td>2020-04-20</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5031</th>\n",
       "      <td>E10000034</td>\n",
       "      <td>Worcestershire</td>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>2020-04-20</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5032</th>\n",
       "      <td>E10000034</td>\n",
       "      <td>Worcestershire</td>\n",
       "      <td>2020-04-18</td>\n",
       "      <td>2020-04-20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5033</th>\n",
       "      <td>E10000034</td>\n",
       "      <td>Worcestershire</td>\n",
       "      <td>2020-04-19</td>\n",
       "      <td>2020-04-20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5034 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           code            name date of cases date reported cases\n",
       "0     E08000025      Birmingham    2020-03-01    2020-04-09     1\n",
       "1     E08000025      Birmingham    2020-03-02    2020-04-09     1\n",
       "2     E08000025      Birmingham    2020-03-05    2020-04-09     1\n",
       "3     E08000025      Birmingham    2020-03-08    2020-04-09     1\n",
       "4     E08000025      Birmingham    2020-03-09    2020-04-09     1\n",
       "...         ...             ...           ...           ...   ...\n",
       "5029  E10000034  Worcestershire    2020-04-15    2020-04-20    40\n",
       "5030  E10000034  Worcestershire    2020-04-16    2020-04-20    35\n",
       "5031  E10000034  Worcestershire    2020-04-17    2020-04-20    26\n",
       "5032  E10000034  Worcestershire    2020-04-18    2020-04-20     2\n",
       "5033  E10000034  Worcestershire    2020-04-19    2020-04-20     0\n",
       "\n",
       "[5034 rows x 5 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_utlas_historical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Old style"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Grab the last JSON in the sorted list, append it to the URL\n",
    "latest_json_url = 'https://c19pub.azureedge.net/' + jsons[-1]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Pull the JSON and convert to a Python object\n",
    "json = requests.get(latest_json_url).json()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Filter to MNA's UTLAs, populate utla_data\n",
    "utla_data = []\n",
    "for (code, data) in json['utlas'].items():\n",
    "    if code in our_utla_codes:\n",
    "        for day in data['dailyConfirmedCases']:\n",
    "            utla_data.append([\n",
    "                code,\n",
    "                data['name']['value'],\n",
    "                day['date'],\n",
    "                day['value']\n",
    "            ])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Create a pandas dataframe from utla_data\n",
    "our_utlas = pd.DataFrame(data=utla_data, columns=['code','name','date','new cases'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def get_latest_cases(codes=False,df=our_utlas.copy()):\n",
    "    if codes:\n",
    "            df = df[df.code.isin(codes)]\n",
    "            \n",
    "    df['cumulative cases'] = df.groupby('code').cumsum()\n",
    "    if codes:\n",
    "            df = df.groupby('date', as_index=False).sum()\n",
    "            \n",
    "    max_date = df['date'].max()\n",
    "    df = df[df['date'] == max_date]\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
